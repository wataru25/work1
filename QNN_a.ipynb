{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLOXFOT5Q40E"
   },
   "source": [
    "# 量子機械学習によるデフォルト予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X35qHdh5Gzqg"
   },
   "source": [
    "## セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-12T21:46:56.852104Z",
     "iopub.status.busy": "2021-02-12T21:46:56.851402Z",
     "iopub.status.idle": "2021-02-12T21:47:05.464928Z",
     "shell.execute_reply": "2021-02-12T21:47:05.464302Z"
    },
    "id": "enZ300Bflq80"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_quantum as tfq\n",
    "\n",
    "import cirq\n",
    "import sympy\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# visualization tools\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from cirq.contrib.svg import SVGCircuit\n",
    "\n",
    "#その他の設定\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b08Mmbs8lr81"
   },
   "source": [
    "## 1. データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path=\"C:/Users/finst/OneDrive/デスクトップ/wataru/13_仕事/量子機械学習/home-credit-default-risk\"\n",
    "path_all_data=main_path+\"/application.csv\" #特徴量データのパス\n",
    "path_testID=main_path+\"/test_key.csv\" #テストデータのID\n",
    "path_trainID=main_path+\"/train_key.csv\" #訓練データのID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDUdGxn-ojgy"
   },
   "source": [
    "### 1.1 生データを読み込む"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZyGXlaKojgz"
   },
   "source": [
    "全てのデータを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-12T21:47:05.471139Z",
     "iopub.status.busy": "2021-02-12T21:47:05.470340Z",
     "iopub.status.idle": "2021-02-12T21:47:05.958603Z",
     "shell.execute_reply": "2021-02-12T21:47:05.957900Z"
    },
    "id": "d9OSExvCojg0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307358, 121)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.read_csv(path_all_data)\n",
    "trainID = pd.read_csv(path_trainID)\n",
    "#IDがかぶっているもののみ抽出\n",
    "ID_overwrap = list(set(all_data.SK_ID_CURR) & set(trainID.SK_ID_CURR))\n",
    "all_data = all_data[all_data.SK_ID_CURR.isin(ID_overwrap)]\n",
    "trainID = trainID[trainID.SK_ID_CURR.isin(ID_overwrap)]\n",
    "\n",
    "#データサイズを確認\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNS9sVPQojhC"
   },
   "source": [
    "### 1.2 データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-12T21:47:06.268678Z",
     "iopub.status.busy": "2021-02-12T21:47:06.267860Z",
     "iopub.status.idle": "2021-02-12T21:47:06.289834Z",
     "shell.execute_reply": "2021-02-12T21:47:06.289273Z"
    },
    "id": "lbhUdBFWojhE"
   },
   "outputs": [],
   "source": [
    "# onehotにする列を指定\n",
    "list_onehot = [\"NAME_TYPE_SUITE\",\"NAME_INCOME_TYPE\",\"NAME_HOUSING_TYPE\",\"NAME_EDUCATION_TYPE\",\n",
    "               \"NAME_FAMILY_STATUS\",\"OCCUPATION_TYPE\",\n",
    "               \"WEEKDAY_APPR_PROCESS_START\",\"ORGANIZATION_TYPE\"]\n",
    "#01に置き換える列を指定\n",
    "list_01 = [\"NAME_CONTRACT_TYPE\",\"CODE_GENDER\",\"FLAG_OWN_CAR\",\"FLAG_OWN_REALTY\"]\n",
    "\n",
    "#量的変数\n",
    "merge =list_onehot+list_01\n",
    "list_quantity = list(set(all_data.columns)-set(merge))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#変数を減らすために実行\n",
    "all_data = all_data[[\"EXT_SOURCE_1\",\"EXT_SOURCE_2\",\"EXT_SOURCE_3\"]]\n",
    "list_quantity=[\"EXT_SOURCE_1\",\"EXT_SOURCE_2\",\"EXT_SOURCE_3\"]\n",
    "for col in [\"EXT_SOURCE_1\",\"EXT_SOURCE_2\",\"EXT_SOURCE_3\"]:\n",
    "    all_data[col]=all_data[col].fillna(all_data[col].mean())\n",
    "    all_data[col]=(all_data[col]-all_data[col].mean())/all_data[col].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#外れ値の処理\n",
    "def outlier_2s(df):\n",
    "\n",
    "    for i in range(len(df.columns)-1):\n",
    "\n",
    "        # 列を抽出する\n",
    "        col = df.iloc[:,i]\n",
    "\n",
    "        # 平均と標準偏差\n",
    "        average = np.mean(col)\n",
    "        sd = np.std(col)\n",
    "\n",
    "        # 外れ値の基準点\n",
    "        outlier_min = average - (sd) * 2\n",
    "        outlier_max = average + (sd) * 2\n",
    "\n",
    "        # 範囲から外れている値を除く\n",
    "        col_name = df.columns[i]\n",
    "        df[df[col_name]<outlier_min]=None\n",
    "        df[df[col_name]>outlier_max]=None\n",
    "\n",
    "        \n",
    "    df = df.dropna(how='any', axis=0)\n",
    "\n",
    "    return df\n",
    "\n",
    "TARGET = trainID[\"TARGET\"].tolist()\n",
    "all_data[\"TARGET\"]=TARGET\n",
    "all_data = outlier_2s(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【データへの変換】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-1～1の範囲に限定する\n",
    "for col in [\"EXT_SOURCE_1\",\"EXT_SOURCE_2\",\"EXT_SOURCE_3\"]:\n",
    "    all_data[col]=all_data[col]/max(all_data[col].abs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【テストデータと訓練データの分割し，アンダーサンプリング】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_data[[\"EXT_SOURCE_1\",\"EXT_SOURCE_2\",\"EXT_SOURCE_3\"]], all_data.TARGET, test_size=0.3, random_state=0)\n",
    "#1の数が圧倒的少ないので，割合を調整\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# クラス1の数を保存\n",
    "count_train_class_one = int(y_train.sum())\n",
    "# クラス1が全体の10％になるまでクラス0を減らす\n",
    "under = RandomUnderSampler(sampling_strategy={0:count_train_class_one, 1:count_train_class_one}, random_state=100)\n",
    "\n",
    "# 学習用データに反映\n",
    "X_train, y_train = under.fit_resample(X_train, y_train)\n",
    "\n",
    "#古典NNのためにデータを保存\n",
    "X_train_c, X_test_c, y_train_c, y_test_c=X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【量子回路への変換】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-12T21:47:06.863174Z",
     "iopub.status.busy": "2021-02-12T21:47:06.824492Z",
     "iopub.status.idle": "2021-02-12T21:47:08.736770Z",
     "shell.execute_reply": "2021-02-12T21:47:08.736090Z"
    },
    "id": "aOu_3-3ZGL61"
   },
   "outputs": [],
   "source": [
    "def convert_to_circuit(credit_info):\n",
    "    qubits = cirq.GridQubit.rect(len(credit_info), 1)\n",
    "    circuit = cirq.Circuit()\n",
    "    for i, value in enumerate(credit_info):\n",
    "        if value:\n",
    "            circuit.append(cirq.X(qubits[i]))\n",
    "    return circuit\n",
    "\n",
    "X_train = X_train.values.tolist()\n",
    "X_test = X_test.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_circ = [convert_to_circuit(x) for x in X_train]\n",
    "x_test_circ = [convert_to_circuit(x) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-12T21:47:08.841947Z",
     "iopub.status.busy": "2021-02-12T21:47:08.836937Z",
     "iopub.status.idle": "2021-02-12T21:47:12.946481Z",
     "shell.execute_reply": "2021-02-12T21:47:12.945795Z"
    },
    "id": "IZStEMk4ojhk"
   },
   "outputs": [],
   "source": [
    "x_train_tfcirc = tfq.convert_to_tensor(x_train_circ)\n",
    "x_test_tfcirc = tfq.convert_to_tensor(x_test_circ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4USiqeOqGL67"
   },
   "source": [
    "## 2. 量子ニューラルネットワーク\n",
    "\n",
    "画像を分類する量子回路構造に関するガイダンスはほとんどありません。分類は読み出されるキュービットの期待に基づいて行われるため、<a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> は、2 つのキュービットゲートを使用して、読み出しキュービットが必ず作用されるようにすることを提案しています。これはある意味、ピクセル全体に小さな<a href=\"https://arxiv.org/abs/1511.06464\" class=\"external\">ユニタリ RNN</a>を実行することに似ています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "knIzawEeojho"
   },
   "source": [
    "### 2.1 モデル回路を構築する\n",
    "\n",
    "次の例では、このレイヤー化アプローチを説明しています。各レイヤーは同一ゲートの *n* 個のインスタンスを使用しており、各データキュービットは読み出しキュービットに影響を与えています。\n",
    "\n",
    "ゲートのレイヤーを回路に追加する簡単なクラスから始めましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-12T21:47:12.953327Z",
     "iopub.status.busy": "2021-02-12T21:47:12.952536Z",
     "iopub.status.idle": "2021-02-12T21:47:12.954836Z",
     "shell.execute_reply": "2021-02-12T21:47:12.954293Z"
    },
    "id": "-hjxxgU5ojho"
   },
   "outputs": [],
   "source": [
    "class CircuitLayerBuilder():\n",
    "    def __init__(self, data_qubits, readout):\n",
    "        self.data_qubits = data_qubits\n",
    "        self.readout = readout\n",
    "    \n",
    "    def add_layer(self, circuit, gate, prefix):\n",
    "        for i, qubit in enumerate(self.data_qubits):\n",
    "            symbol = sympy.Symbol(prefix + '-' + str(i))\n",
    "            circuit.append(gate(qubit, self.readout)**symbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-QhPE1pojhu"
   },
   "source": [
    "では、2 レイヤーモデルを構築しましょう。 データ回路サイズに一致するようにし、準備と読み出し演算を含めます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-12T21:47:13.098934Z",
     "iopub.status.busy": "2021-02-12T21:47:13.098236Z",
     "iopub.status.idle": "2021-02-12T21:47:13.100221Z",
     "shell.execute_reply": "2021-02-12T21:47:13.099728Z"
    },
    "id": "JiALbpwRGL69"
   },
   "outputs": [],
   "source": [
    "def create_quantum_model():\n",
    "    \"\"\"Create a QNN model circuit and readout operation to go along with it.\"\"\"\n",
    "    data_qubits = cirq.GridQubit.rect(len(X_train[0]), 1)  \n",
    "    readout = cirq.GridQubit(-1, -1)         # a single qubit at [-1,-1]\n",
    "    circuit = cirq.Circuit()\n",
    "    \n",
    "    # Prepare the readout qubit.\n",
    "    circuit.append(cirq.X(readout))\n",
    "    circuit.append(cirq.H(readout))\n",
    "    \n",
    "    builder = CircuitLayerBuilder(\n",
    "        data_qubits = data_qubits,\n",
    "        readout=readout)\n",
    "\n",
    "    # Then add layers (experiment by adding more).\n",
    "    builder.add_layer(circuit, cirq.XX, \"xx1\")\n",
    "    builder.add_layer(circuit, cirq.ZZ, \"zz1\")\n",
    "\n",
    "    # Finally, prepare the readout qubit.\n",
    "    circuit.append(cirq.H(readout))\n",
    "\n",
    "    return circuit, cirq.Z(readout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-12T21:47:13.117552Z",
     "iopub.status.busy": "2021-02-12T21:47:13.116825Z",
     "iopub.status.idle": "2021-02-12T21:47:13.118922Z",
     "shell.execute_reply": "2021-02-12T21:47:13.118424Z"
    },
    "id": "2QZvVh7vojhx"
   },
   "outputs": [],
   "source": [
    "model_circuit, model_readout = create_quantum_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LY7vbY6yfABE"
   },
   "source": [
    "### 2.2 tfq-keras モデルでモデル回路をラップする\n",
    "\n",
    "量子コンポーネントで Keras モデルを構築します。このモデルには、古典的なデータをエンコードする「量子データ」が `x_train_circ` からフィードされます。*パラメータ化された量子回路*レイヤーの `tfq.layers.PQC` を使用して、量子データでモデル回路をトレーニングするモデルです。\n",
    "\n",
    "<a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> は、画像を分類するには、パラメータ化された回路で読み出しキュービットの期待値を使用することを提案しています。期待値は、1 から -1 の値です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-12T21:47:13.125437Z",
     "iopub.status.busy": "2021-02-12T21:47:13.123050Z",
     "iopub.status.idle": "2021-02-12T21:47:14.138442Z",
     "shell.execute_reply": "2021-02-12T21:47:14.138925Z"
    },
    "id": "ZYdf_KOxojh0"
   },
   "outputs": [],
   "source": [
    "# Build the Keras model.\n",
    "model = tf.keras.Sequential([\n",
    "    # The input is the data-circuit, encoded as a tf.string\n",
    "    tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
    "    # The PQC layer returns the expected value of the readout gate, range [-1,1].\n",
    "    tfq.layers.PQC(model_circuit, model_readout),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jz-FbVc9ojh3"
   },
   "source": [
    "次に、`compile` メソッドを使用して、モデルにトレーニング手順を指定します。\n",
    "\n",
    "期待される読み出しは `[-1,1]` の範囲であるため、ヒンジ損失を最適化すると、ある程度自然な適合となります。\n",
    "\n",
    "注意: もう 1 つの有効なアプローチとして、出力範囲を `[0,1]` にシフトし、モデルがクラス `3` に割りてる確率として扱う方法があります。これは、標準的な`tf.losses.BinaryCrossentropy` 損失で使用することができます。\n",
    "\n",
    "ここでヒンジ損失を使用するには、小さな調整を 2 つ行う必要があります。まず、ラベル `y_train_nocon` をブール型からヒンジ損失が期待する `[-1,1]` に変換することです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-12T21:47:14.144266Z",
     "iopub.status.busy": "2021-02-12T21:47:14.143270Z",
     "iopub.status.idle": "2021-02-12T21:47:14.145667Z",
     "shell.execute_reply": "2021-02-12T21:47:14.146100Z"
    },
    "id": "CgMNkC1Fojh5"
   },
   "outputs": [],
   "source": [
    "y_train_hinge = 2.0*y_train-1.0\n",
    "y_test_hinge = 2.0*y_test-1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5nwnveDiojh7"
   },
   "source": [
    "次に、`[-1, 1]` を `y_true` ラベル引数として正しく処理するカスタムの `hinge_accuracy` メトリックを使用します。`tf.losses.BinaryAccuracy(threshold=0.0)` は `y_true` がブール型であることを期待するため、ヒンジ損失とは使用できません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-12T21:47:14.152616Z",
     "iopub.status.busy": "2021-02-12T21:47:14.151434Z",
     "iopub.status.idle": "2021-02-12T21:47:14.154049Z",
     "shell.execute_reply": "2021-02-12T21:47:14.153410Z"
    },
    "id": "3XKtZ_TEojh8"
   },
   "outputs": [],
   "source": [
    "def hinge_accuracy(y_true, y_pred):\n",
    "    y_true = tf.squeeze(y_true) > 0.0\n",
    "    y_pred = tf.squeeze(y_pred) > 0.0\n",
    "    result = tf.cast(y_true == y_pred, tf.float32)\n",
    "\n",
    "    return tf.reduce_mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-12T21:47:14.165022Z",
     "iopub.status.busy": "2021-02-12T21:47:14.163932Z",
     "iopub.status.idle": "2021-02-12T21:47:14.181630Z",
     "shell.execute_reply": "2021-02-12T21:47:14.181097Z"
    },
    "id": "FlpETlLRojiA"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.Hinge(),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[hinge_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-12T21:47:14.187525Z",
     "iopub.status.busy": "2021-02-12T21:47:14.186673Z",
     "iopub.status.idle": "2021-02-12T21:47:14.190129Z",
     "shell.execute_reply": "2021-02-12T21:47:14.189639Z"
    },
    "id": "jkHq2RstojiC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "pqc_3 (PQC)                  (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsuOzDYblA9s"
   },
   "source": [
    "### 量子モデルをトレーニングする\n",
    "\n",
    "では、モデルをトレーニングしましょう。これには約 45 分かかりますが、その時間を待てない方は、小規模なデータのサブセット（以下の`NUM_EXAMPLES=500` セット）を使用するとよいでしょう。トレーニング時のモデルの進捗にあまり影響はありません（パラメータは 32 しかなく、これらを制約する上であまりデータは必要ありません）。サンプル数を減らすことでトレーニングを早めに（5 分程度）終わらせることができますが、検証ログに進捗状況を示すには十分な長さです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-12T21:47:14.194907Z",
     "iopub.status.busy": "2021-02-12T21:47:14.193896Z",
     "iopub.status.idle": "2021-02-12T21:47:14.196533Z",
     "shell.execute_reply": "2021-02-12T21:47:14.196052Z"
    },
    "id": "n8vuQpSLlBV2"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMSdgGC1GL7D"
   },
   "source": [
    "このモデルを収束までトレーニングすると、テストセットにおいて 85% を超える精度が達成されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-12T21:47:14.211232Z",
     "iopub.status.busy": "2021-02-12T21:47:14.208064Z",
     "iopub.status.idle": "2021-02-12T21:55:12.617657Z",
     "shell.execute_reply": "2021-02-12T21:55:12.616947Z"
    },
    "id": "Ya9qP3KkojiM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23328 samples, validate on 75666 samples\n",
      "Epoch 1/3\n",
      "23328/23328 [==============================] - 7s 320us/sample - loss: 1.0001 - hinge_accuracy: 0.5000 - val_loss: 0.8258 - val_hinge_accuracy: 0.9344\n",
      "Epoch 2/3\n",
      "23328/23328 [==============================] - 7s 306us/sample - loss: 1.0001 - hinge_accuracy: 0.4996 - val_loss: 0.8183 - val_hinge_accuracy: 0.9344\n",
      "Epoch 3/3\n",
      "23328/23328 [==============================] - 7s 309us/sample - loss: 1.0002 - hinge_accuracy: 0.5000 - val_loss: 0.8333 - val_hinge_accuracy: 0.9344\n",
      "75666/75666 [==============================] - 4s 55us/sample - loss: 0.8333 - hinge_accuracy: 0.9344\n"
     ]
    }
   ],
   "source": [
    "qnn_history = model.fit(\n",
    "      x_train_tfcirc, y_train_hinge,\n",
    "      batch_size=BATCH_SIZE,\n",
    "      epochs=EPOCHS,\n",
    "      verbose=1,\n",
    "      validation_data=(x_test_tfcirc, y_test_hinge))\n",
    "\n",
    "qnn_results = model.evaluate(x_test_tfcirc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.19192085],\n",
       "       [-0.19192085],\n",
       "       [-0.19192085],\n",
       "       ...,\n",
       "       [-0.19192085],\n",
       "       [-0.19192085],\n",
       "       [-0.19192085]], dtype=float32)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test_tfcirc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ER7B7aaojiP"
   },
   "source": [
    "注意: トレーニング精度はエポックの平均値を示します。検証精度はエポックの終了ごとに評価されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8952YvuWGL7J"
   },
   "source": [
    "## 3. 従来のニューラルネットワーク\n",
    "\n",
    "量子ニューラルネットワークは、この単純化された MNIST 問題で機能するものの、このタスクでは、従来のニューラルネットワークの性能が QNN をはるかに上回ります。1 つのエポックが終了した時点で、従来のニューラルネットワークは縮小したセットで 98% を超える精度を達成することができます。\n",
    "\n",
    "次の例では、画像をサブサンプリングする代わりに 28x28 の画像を使用した 3 と 6 の分類問題に従来のニューラルネットワークを使用しています。これはほぼ 100% 精度のテストセットに難なく収束します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-12T21:55:12.629267Z",
     "iopub.status.busy": "2021-02-12T21:55:12.628113Z",
     "iopub.status.idle": "2021-02-12T21:55:12.715962Z",
     "shell.execute_reply": "2021-02-12T21:55:12.715222Z"
    },
    "id": "pZofEHhLGL7L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_classical_model():\n",
    "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
    "    model = tf.keras.Sequential()\n",
    "    #model.add(tf.keras.layers.Conv2D(32, [3, 3], activation='relu', input_shape=(28,28,1)))\n",
    "    #model.add(tf.keras.layers.Conv2D(64, [3, 3], activation='relu'))\n",
    "    #model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(tf.keras.layers.Dropout(0.25))\n",
    "    #model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(10, activation='relu',input_shape = (3,)))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(5, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_classical_model()\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-12T21:55:12.721646Z",
     "iopub.status.busy": "2021-02-12T21:55:12.720947Z",
     "iopub.status.idle": "2021-02-12T21:55:22.054724Z",
     "shell.execute_reply": "2021-02-12T21:55:22.055201Z"
    },
    "id": "CiAJl7sZojiU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23328 samples, validate on 75666 samples\n",
      "23328/23328 [==============================] - 1s 26us/sample - loss: 0.6808 - accuracy: 0.5057 - val_loss: 0.6615 - val_accuracy: 0.9332\n",
      "75666/75666 [==============================] - 1s 10us/sample - loss: 0.6615 - accuracy: 0.9332\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_c,\n",
    "          y_train_c,\n",
    "          batch_size=128,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_c, y_test_c))\n",
    "\n",
    "cnn_results = model.evaluate(X_test_c, y_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1150108 ],\n",
       "       [ 0.22811824],\n",
       "       [-0.43930542],\n",
       "       ...,\n",
       "       [-0.36513916],\n",
       "       [-0.1921977 ],\n",
       "       [ 0.25203726]], dtype=float32)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RH3mam7EGL7N"
   },
   "source": [
    "## 4. 比較\n",
    "\n",
    "解像度の高い入力とより強力なモデルの場合、CNN はこの問題を簡単に解決できますが、似たようなパワー（最大 32 個のパラメータ）を持つ古典的モデルはわずかな時間で似たような精度までトレーニングすることができます。いずれにせよ、従来のニューラルネットワークは量子ニューラルネットワークの性能を簡単に上回ります。古典的なデータでは、従来のニューラルネットワークを上回るのは困難といえます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-12T21:55:24.779995Z",
     "iopub.status.busy": "2021-02-12T21:55:24.761298Z",
     "iopub.status.idle": "2021-02-12T21:55:24.869075Z",
     "shell.execute_reply": "2021-02-12T21:55:24.868509Z"
    },
    "id": "NOMeN7pMGL7P"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\quantum\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "qnn_accuracy = qnn_results[1]\n",
    "cnn_accuracy = cnn_results[1]\n",
    "\n",
    "\n",
    "sns.barplot([\"Quantum\", \"Classical, full\"],\n",
    "            [qnn_accuracy, cnn_accuracy ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "mnist.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
